{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJZW6XWQCSlS",
        "outputId": "9c886d57-e0e7-4d73-cf34-5551855cf627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n"
          ]
        }
      ],
      "source": [
        "pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt6G3XS5CelH",
        "outputId": "8b9be3c9-5389-46b0-8e57-642661819827"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBoxHorizontal, LTTextLineHorizontal, LTChar\n",
        "from typing import List, Dict, Any\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class SectionContainer:\n",
        "    \"\"\"Container to store parsed content and metadata.\"\"\"\n",
        "    def __init__(self, content: str, metadata: Dict[str, Any]):\n",
        "        self.content = content\n",
        "        self.metadata = metadata\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"SectionContainer(metadata={self.metadata}, content_length={len(self.content)})\"\n",
        "\n",
        "\n",
        "def analyze_pdf_layout(pdf_path: str):\n",
        "    \"\"\"Analyzes the layout of a PDF to understand its structure.\"\"\"\n",
        "    layout_data = []\n",
        "    for page_layout in extract_pages(pdf_path):\n",
        "        page_elements = []\n",
        "        for element in page_layout:\n",
        "            if isinstance(element, LTTextBoxHorizontal):\n",
        "                for line in element:\n",
        "                    if isinstance(line, LTTextLineHorizontal):\n",
        "                        font_size = max(\n",
        "                            (char.size for char in line if isinstance(char, LTChar)),\n",
        "                            default=0,\n",
        "                        )\n",
        "                        font_name = max(\n",
        "                            (char.fontname for char in line if isinstance(char, LTChar)),\n",
        "                            default=\"\",\n",
        "                        )\n",
        "                        text = line.get_text().strip()\n",
        "                        page_elements.append({\"text\": text, \"font_size\": font_size, \"font_style\": font_name})\n",
        "        layout_data.append(page_elements)\n",
        "    return layout_data\n",
        "\n",
        "\n",
        "def parse_pdf_content(pdf_path: str) -> List[SectionContainer]:\n",
        "    \"\"\"Parses PDF content and organizes it into containers with metadata.\"\"\"\n",
        "    containers = []\n",
        "    layout_analysis = analyze_pdf_layout(pdf_path)\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            metadata = {\"page_number\": page_num}\n",
        "\n",
        "            # Group text by font size and style\n",
        "            font_size_hierarchy = {}\n",
        "            for element in layout_analysis[page_num - 1]:\n",
        "                if \"text\" in element:\n",
        "                    rounded_font_size = round(element[\"font_size\"])\n",
        "                    key = (rounded_font_size, element[\"font_style\"])\n",
        "                    font_size_hierarchy.setdefault(key, []).append(element[\"text\"])\n",
        "\n",
        "            for (font_size, font_style), texts in font_size_hierarchy.items():\n",
        "                combined_text = \"\\n\".join(texts)\n",
        "                metadata[\"font_size\"] = font_size\n",
        "                metadata[\"font_style\"] = font_style\n",
        "                metadata[\"content_length\"] = len(combined_text)\n",
        "\n",
        "                # Exclude sections with content length <= 3\n",
        "                if len(combined_text) > 3:\n",
        "                    containers.append(SectionContainer(content=combined_text, metadata=metadata.copy()))\n",
        "\n",
        "    return containers\n",
        "\n",
        "\n",
        "def group_by_top_font_sizes(parsed_sections: List[SectionContainer], top_n: int = 5) -> Dict[int, Dict[str, List[Dict[str, Any]]]]:\n",
        "    \"\"\"Groups sections by rounded font size and font style, keeping only the top N font sizes.\"\"\"\n",
        "    grouped_data = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "    # Collect all unique font sizes\n",
        "    font_sizes = sorted(\n",
        "        {section.metadata[\"font_size\"] for section in parsed_sections},\n",
        "        reverse=True,\n",
        "    )\n",
        "\n",
        "    # Select the top N font sizes\n",
        "    top_font_sizes = font_sizes[:top_n]\n",
        "\n",
        "    for section in parsed_sections:\n",
        "        font_size = section.metadata[\"font_size\"]\n",
        "        if font_size in top_font_sizes:\n",
        "            font_style = section.metadata[\"font_style\"]\n",
        "            grouped_data[font_size][font_style].append({\n",
        "                \"content\": section.content,\n",
        "                \"page_number\": section.metadata[\"page_number\"],\n",
        "                \"content_length\": section.metadata[\"content_length\"],\n",
        "            })\n",
        "\n",
        "    return grouped_data\n",
        "\n",
        "\n",
        "def save_grouped_sections_to_file(grouped_sections: Dict[int, Dict[str, List[Dict[str, Any]]]], output_file: str):\n",
        "    \"\"\"Saves grouped sections to a text file.\"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for font_size, styles in sorted(grouped_sections.items(), reverse=True):\n",
        "            f.write(f\"Font Size: {font_size}\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\")\n",
        "            for font_style, sections in styles.items():\n",
        "                f.write(f\"  Font Style: {font_style}\\n\")\n",
        "                f.write(\"  \" + \"-\" * 45 + \"\\n\")\n",
        "                for section in sections:\n",
        "                    f.write(f\"    Page Number: {section['page_number']}\\n\")\n",
        "\n",
        "                    # Include content or content length conditionally\n",
        "                    if section[\"content_length\"] <= 100:\n",
        "                        f.write(f\"    Content: {section['content']}\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"    Content Length: {section['content_length']}\\n\")\n",
        "\n",
        "                    f.write(\"\\n\")\n",
        "                f.write(\"  \" + \"-\" * 45 + \"\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"  # Replace with your PDF path\n",
        "    output_file = \"/content/top_font_sizes.txt\"  # Replace with desired output path\n",
        "\n",
        "    parsed_sections = parse_pdf_content(pdf_path)\n",
        "    grouped_sections = group_by_top_font_sizes(parsed_sections, top_n=5)\n",
        "    save_grouped_sections_to_file(grouped_sections, output_file)\n",
        "\n",
        "    print(f\"Top 5 font sizes saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MelloNrmCenF",
        "outputId": "2b4db243-0068-4e42-cee3-f7aedd423f62"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 font sizes saved to /content/top_font_sizes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTImage, LTFigure\n",
        "from pdfplumber import open as pdfplumber_open\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        \"\"\"Load the configuration file containing font size and style for headings.\"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        \"\"\"Identify the average font size and style for a line.\"\"\"\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))  # Round off font size\n",
        "                font_styles.add(char.fontname)\n",
        "\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0  # Round average font size\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        \"\"\"Match the font size and style with the config to classify the heading.\"\"\"\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size >= attributes['font_size'] and attributes['font_style'] in font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        \"\"\"Parse table content using pdfplumber.\"\"\"\n",
        "        with pdfplumber_open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, page_number, pdf_path):\n",
        "        \"\"\"Process each element (text, table, or image) and store it appropriately.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        # Append to the title if it's a continuation\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        # Save previous content before starting a new section\n",
        "                        if current_section or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content = []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        # Save previous content before starting a new subsection\n",
        "                        if current_subsection or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content = []\n",
        "                    else:\n",
        "                        # Regular content\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Handle figures (e.g., tables or images)\n",
        "            tables = self.parse_table(pdf_path, page_number)\n",
        "            if tables:\n",
        "                # Append table information to the current content without creating a separate entry\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": tables,\n",
        "                    \"Image\": []\n",
        "                })\n",
        "                content = []  # Clear content after adding table info\n",
        "\n",
        "        elif isinstance(element, LTImage):\n",
        "            # Handle images\n",
        "            content.append(\"[Image detected]\")\n",
        "\n",
        "        return current_section, current_subsection, content\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        \"\"\"Parse the PDF using pdfminer and include page numbers.\"\"\"\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content = []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content = self.process_element(\n",
        "                    element, current_section, current_subsection, content, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        # Merge last content into the last dictionary\n",
        "        if self.result and content:\n",
        "            self.result[-1][\"Raw Content\"] += \" \" + \" \".join(content)\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"  # Path to the config file\n",
        "pdf_path = \"/content/00050107-Generative-AI-pt-ai-Zant-Kouw-Schomaker.pdf\"  # Path to the PDF\n",
        "\n",
        "# Document name for identification\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "# Initialize and parse\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "# Save the parsed content to a JSON file\n",
        "with open(\"parsed_content.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "b4aIzvmbCeoC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTImage, LTFigure\n",
        "from pdfplumber import open as pdfplumber_open\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        \"\"\"Load the configuration file containing font size and style for headings.\"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        \"\"\"Identify the average font size and style for a line.\"\"\"\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))  # Round off font size\n",
        "                font_styles.add(char.fontname)\n",
        "\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0  # Round average font size\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        \"\"\"Match the font size and style with the config to classify the heading.\"\"\"\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        \"\"\"Parse table content using pdfplumber.\"\"\"\n",
        "        with pdfplumber_open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, page_number, pdf_path):\n",
        "        \"\"\"Process each element (text, table, or image) and store it appropriately.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        # Append to the title if it's a continuation\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        # Save previous content before starting a new section\n",
        "                        if current_section or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content = []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        # Save previous content before starting a new subsection\n",
        "                        if current_subsection or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content = []\n",
        "                    else:\n",
        "                        # Regular content\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Handle figures (e.g., tables or images)\n",
        "            tables = self.parse_table(pdf_path, page_number)\n",
        "            if tables:\n",
        "                # Append table information to the current content without creating a separate entry\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": tables,\n",
        "                    \"Image\": []\n",
        "                })\n",
        "                content = []  # Clear content after adding table info\n",
        "\n",
        "        elif isinstance(element, LTImage):\n",
        "            # Handle images\n",
        "            content.append(\"[Image detected]\")\n",
        "\n",
        "        return current_section, current_subsection, content\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        \"\"\"Parse the PDF using pdfminer and include page numbers.\"\"\"\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content = []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content = self.process_element(\n",
        "                    element, current_section, current_subsection, content, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        # Merge last content into the last dictionary only if it contains a table or image\n",
        "        if self.result and content:\n",
        "            last_entry = self.result[-1]\n",
        "            if last_entry[\"Tables\"] or \"[Image detected]\" in last_entry[\"Raw Content\"]:\n",
        "                last_entry[\"Raw Content\"] += \" \" + \" \".join(content)\n",
        "            else:\n",
        "                # Create a new dictionary for remaining content\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": [],\n",
        "                    \"Image\": []\n",
        "                })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"  # Path to the config file\n",
        "pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"  # Path to the PDF\n",
        "\n",
        "# Document name for identification\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "# Initialize and parse\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "# Save the parsed content to a JSON file\n",
        "with open(\"parsed_content_fixed_3.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "0a09LMTzCez1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvNYQL45Ce2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}