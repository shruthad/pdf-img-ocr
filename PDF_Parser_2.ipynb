{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJZW6XWQCSlS",
        "outputId": "71a25281-08fc-4ed3-e899-232e457435da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/5.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ],
      "source": [
        "pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt6G3XS5CelH",
        "outputId": "2ec89557-95af-4b54-d0b2-09d4cc8bfb64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20240706\n",
            "    Uninstalling pdfminer.six-20240706:\n",
            "      Successfully uninstalled pdfminer.six-20240706\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBoxHorizontal, LTTextLineHorizontal, LTChar\n",
        "from typing import List, Dict, Any\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class SectionContainer:\n",
        "    \"\"\"Container to store parsed content and metadata.\"\"\"\n",
        "    def __init__(self, content: str, metadata: Dict[str, Any]):\n",
        "        self.content = content\n",
        "        self.metadata = metadata\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"SectionContainer(metadata={self.metadata}, content_length={len(self.content)})\"\n",
        "\n",
        "\n",
        "def analyze_pdf_layout(pdf_path: str):\n",
        "    \"\"\"Analyzes the layout of a PDF to understand its structure.\"\"\"\n",
        "    layout_data = []\n",
        "    for page_layout in extract_pages(pdf_path):\n",
        "        page_elements = []\n",
        "        for element in page_layout:\n",
        "            if isinstance(element, LTTextBoxHorizontal):\n",
        "                for line in element:\n",
        "                    if isinstance(line, LTTextLineHorizontal):\n",
        "                        font_size = max(\n",
        "                            (char.size for char in line if isinstance(char, LTChar)),\n",
        "                            default=0,\n",
        "                        )\n",
        "                        font_name = max(\n",
        "                            (char.fontname for char in line if isinstance(char, LTChar)),\n",
        "                            default=\"\",\n",
        "                        )\n",
        "                        text = line.get_text().strip()\n",
        "                        page_elements.append({\"text\": text, \"font_size\": font_size, \"font_style\": font_name})\n",
        "        layout_data.append(page_elements)\n",
        "    return layout_data\n",
        "\n",
        "\n",
        "def parse_pdf_content(pdf_path: str) -> List[SectionContainer]:\n",
        "    \"\"\"Parses PDF content and organizes it into containers with metadata.\"\"\"\n",
        "    containers = []\n",
        "    layout_analysis = analyze_pdf_layout(pdf_path)\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            metadata = {\"page_number\": page_num}\n",
        "\n",
        "            # Group text by font size and style\n",
        "            font_size_hierarchy = {}\n",
        "            for element in layout_analysis[page_num - 1]:\n",
        "                if \"text\" in element:\n",
        "                    rounded_font_size = round(element[\"font_size\"])\n",
        "                    key = (rounded_font_size, element[\"font_style\"])\n",
        "                    font_size_hierarchy.setdefault(key, []).append(element[\"text\"])\n",
        "\n",
        "            for (font_size, font_style), texts in font_size_hierarchy.items():\n",
        "                combined_text = \"\\n\".join(texts)\n",
        "                metadata[\"font_size\"] = font_size\n",
        "                metadata[\"font_style\"] = font_style\n",
        "                metadata[\"content_length\"] = len(combined_text)\n",
        "\n",
        "                # Exclude sections with content length <= 3\n",
        "                if len(combined_text) > 3:\n",
        "                    containers.append(SectionContainer(content=combined_text, metadata=metadata.copy()))\n",
        "\n",
        "    return containers\n",
        "\n",
        "\n",
        "def group_by_top_font_sizes(parsed_sections: List[SectionContainer], top_n: int = 5) -> Dict[int, Dict[str, List[Dict[str, Any]]]]:\n",
        "    \"\"\"Groups sections by rounded font size and font style, keeping only the top N font sizes.\"\"\"\n",
        "    grouped_data = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "    # Collect all unique font sizes\n",
        "    font_sizes = sorted(\n",
        "        {section.metadata[\"font_size\"] for section in parsed_sections},\n",
        "        reverse=True,\n",
        "    )\n",
        "\n",
        "    # Select the top N font sizes\n",
        "    top_font_sizes = font_sizes[:top_n]\n",
        "\n",
        "    for section in parsed_sections:\n",
        "        font_size = section.metadata[\"font_size\"]\n",
        "        if font_size in top_font_sizes:\n",
        "            font_style = section.metadata[\"font_style\"]\n",
        "            grouped_data[font_size][font_style].append({\n",
        "                \"content\": section.content,\n",
        "                \"page_number\": section.metadata[\"page_number\"],\n",
        "                \"content_length\": section.metadata[\"content_length\"],\n",
        "            })\n",
        "\n",
        "    return grouped_data\n",
        "\n",
        "\n",
        "def save_grouped_sections_to_file(grouped_sections: Dict[int, Dict[str, List[Dict[str, Any]]]], output_file: str):\n",
        "    \"\"\"Saves grouped sections to a text file.\"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for font_size, styles in sorted(grouped_sections.items(), reverse=True):\n",
        "            f.write(f\"Font Size: {font_size}\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\")\n",
        "            for font_style, sections in styles.items():\n",
        "                f.write(f\"  Font Style: {font_style}\\n\")\n",
        "                f.write(\"  \" + \"-\" * 45 + \"\\n\")\n",
        "                for section in sections:\n",
        "                    f.write(f\"    Page Number: {section['page_number']}\\n\")\n",
        "\n",
        "                    # Include content or content length conditionally\n",
        "                    if section[\"content_length\"] <= 120:\n",
        "                        f.write(f\"    Content: {section['content']}\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"    Content Length: {section['content_length']}\\n\")\n",
        "\n",
        "                    f.write(\"\\n\")\n",
        "                f.write(\"  \" + \"-\" * 45 + \"\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/content/1807.01544v2-2.pdf\"  # Replace with your PDF path\n",
        "    output_file = \"/content/top_font_sizes.txt\"  # Replace with desired output path\n",
        "\n",
        "    parsed_sections = parse_pdf_content(pdf_path)\n",
        "    grouped_sections = group_by_top_font_sizes(parsed_sections, top_n=5)\n",
        "    save_grouped_sections_to_file(grouped_sections, output_file)\n",
        "\n",
        "    print(f\"Top 5 font sizes saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MelloNrmCenF",
        "outputId": "4b57243e-9a4f-4e05-9e00-a44c5cf3ddc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 font sizes saved to /content/top_font_sizes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTImage, LTFigure\n",
        "from pdfplumber import open as pdfplumber_open\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        \"\"\"Load the configuration file containing font size and style for headings.\"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        \"\"\"Identify the average font size and style for a line.\"\"\"\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))  # Round off font size\n",
        "                font_styles.add(char.fontname)\n",
        "\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0  # Round average font size\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        \"\"\"Match the font size and style with the config to classify the heading.\"\"\"\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size >= attributes['font_size'] and attributes['font_style'] in font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        \"\"\"Parse table content using pdfplumber.\"\"\"\n",
        "        with pdfplumber_open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, page_number, pdf_path):\n",
        "        \"\"\"Process each element (text, table, or image) and store it appropriately.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        # Append to the title if it's a continuation\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        # Save previous content before starting a new section\n",
        "                        if current_section or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content = []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        # Save previous content before starting a new subsection\n",
        "                        if current_subsection or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content = []\n",
        "                    else:\n",
        "                        # Regular content\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Handle figures (e.g., tables or images)\n",
        "            tables = self.parse_table(pdf_path, page_number)\n",
        "            if tables:\n",
        "                # Append table information to the current content without creating a separate entry\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": tables,\n",
        "                    \"Image\": []\n",
        "                })\n",
        "                content = []  # Clear content after adding table info\n",
        "\n",
        "        elif isinstance(element, LTImage):\n",
        "            # Handle images\n",
        "            content.append(\"[Image detected]\")\n",
        "\n",
        "        return current_section, current_subsection, content\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        \"\"\"Parse the PDF using pdfminer and include page numbers.\"\"\"\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content = []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content = self.process_element(\n",
        "                    element, current_section, current_subsection, content, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        # Merge last content into the last dictionary\n",
        "        if self.result and content:\n",
        "            self.result[-1][\"Raw Content\"] += \" \" + \" \".join(content)\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"  # Path to the config file\n",
        "pdf_path = \"/content/00050107-Generative-AI-pt-ai-Zant-Kouw-Schomaker.pdf\"  # Path to the PDF\n",
        "\n",
        "# Document name for identification\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "# Initialize and parse\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "# Save the parsed content to a JSON file\n",
        "with open(\"parsed_content.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "b4aIzvmbCeoC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTImage, LTFigure\n",
        "from pdfplumber import open as pdfplumber_open\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        \"\"\"Load the configuration file containing font size and style for headings.\"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        \"\"\"Identify the average font size and style for a line.\"\"\"\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))  # Round off font size\n",
        "                font_styles.add(char.fontname)\n",
        "\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0  # Round average font size\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        \"\"\"Match the font size and style with the config to classify the heading.\"\"\"\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        \"\"\"Parse table content using pdfplumber.\"\"\"\n",
        "        with pdfplumber_open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, page_number, pdf_path):\n",
        "        \"\"\"Process each element (text, table, or image) and store it appropriately.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        # Append to the title if it's a continuation\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        # Save previous content before starting a new section\n",
        "                        if current_section or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content = []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        # Save previous content before starting a new subsection\n",
        "                        if current_subsection or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content = []\n",
        "                    else:\n",
        "                        # Regular content\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Handle figures (e.g., tables or images)\n",
        "            tables = self.parse_table(pdf_path, page_number)\n",
        "            if tables:\n",
        "                # Append table information to the current content without creating a separate entry\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": tables,\n",
        "                    \"Image\": []\n",
        "                })\n",
        "                content = []  # Clear content after adding table info\n",
        "\n",
        "        elif isinstance(element, LTImage):\n",
        "            # Handle images\n",
        "            content.append(\"[Image detected]\")\n",
        "\n",
        "        return current_section, current_subsection, content\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        \"\"\"Parse the PDF using pdfminer and include page numbers.\"\"\"\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content = []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content = self.process_element(\n",
        "                    element, current_section, current_subsection, content, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        # Merge last content into the last dictionary only if it contains a table or image\n",
        "        if self.result and content:\n",
        "            last_entry = self.result[-1]\n",
        "            if last_entry[\"Tables\"] or \"[Image detected]\" in last_entry[\"Raw Content\"]:\n",
        "                last_entry[\"Raw Content\"] += \" \" + \" \".join(content)\n",
        "            else:\n",
        "                # Create a new dictionary for remaining content\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": [],\n",
        "                    \"Image\": []\n",
        "                })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"  # Path to the config file\n",
        "pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"  # Path to the PDF\n",
        "\n",
        "# Document name for identification\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "# Initialize and parse\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "# Save the parsed content to a JSON file\n",
        "with open(\"parsed_content_fixed_11.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "0a09LMTzCez1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTImage, LTFigure\n",
        "from pdfplumber import open as pdfplumber_open\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        \"\"\"Load the configuration file containing font size and style for headings.\"\"\"\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        \"\"\"Identify the average font size and style for a line.\"\"\"\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))  # Round off font size\n",
        "                font_styles.add(char.fontname)\n",
        "\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0  # Round average font size\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        \"\"\"Match the font size and style with the config to classify the heading.\"\"\"\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        \"\"\"Parse table content using pdfplumber.\"\"\"\n",
        "        with pdfplumber_open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, page_number, pdf_path):\n",
        "        \"\"\"Process each element (text, table, or image) and store it appropriately.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        # Append to the title if it's a continuation\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        # Save previous content before starting a new section\n",
        "                        if current_section or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content = []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        # Save previous content before starting a new subsection\n",
        "                        if current_subsection or content:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": [],\n",
        "                                \"Image\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content = []\n",
        "                    else:\n",
        "                        # Regular content\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Handle figures (e.g., tables or images)\n",
        "            tables = self.parse_table(pdf_path, page_number)\n",
        "            if tables:\n",
        "                # Append table information to the current content instead of creating a new entry\n",
        "                if self.result and (current_section or current_subsection):\n",
        "                    last_entry = self.result[-1]\n",
        "                    if last_entry[\"Sections Heading\"] == current_section and last_entry[\"Subsections Heading\"] == current_subsection:\n",
        "                        last_entry[\"Tables\"].extend(tables)\n",
        "                        last_entry[\"Page Number\"] = page_number  # Update page number if necessary\n",
        "                        return current_section, current_subsection, content\n",
        "\n",
        "                # If no matching section/subsection exists, create a new entry\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": tables,\n",
        "                    \"Image\": []\n",
        "                })\n",
        "                content = []  # Clear content after adding table info\n",
        "\n",
        "        elif isinstance(element, LTImage):\n",
        "            # Handle images\n",
        "            content.append(\"[Image detected]\")\n",
        "\n",
        "        return current_section, current_subsection, content\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        \"\"\"Parse the PDF using pdfminer and include page numbers.\"\"\"\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content = []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content = self.process_element(\n",
        "                    element, current_section, current_subsection, content, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        # Merge last content into the last dictionary only if it contains a table or image\n",
        "        if self.result and content:\n",
        "            last_entry = self.result[-1]\n",
        "            if last_entry[\"Tables\"] or \"[Image detected]\" in last_entry[\"Raw Content\"]:\n",
        "                last_entry[\"Raw Content\"] += \" \" + \" \".join(content)\n",
        "            else:\n",
        "                # Create a new dictionary for remaining content\n",
        "                self.result.append({\n",
        "                    \"Document Name\": self.doc_name,\n",
        "                    \"Title\": self.title,\n",
        "                    \"Sections Heading\": current_section or \"\",\n",
        "                    \"Subsections Heading\": current_subsection or \"\",\n",
        "                    \"Raw Content\": \" \".join(content),\n",
        "                    \"Page Number\": page_number,\n",
        "                    \"Tables\": [],\n",
        "                    \"Image\": []\n",
        "                })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"  # Path to the config file\n",
        "pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"  # Path to the PDF\n",
        "\n",
        "# Document name for identification\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "# Initialize and parse\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "# Save the parsed content to a JSON file\n",
        "with open(\"parsed_content_fixed.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "wvNYQL45Ce2Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTFigure,LTRect\n",
        "import pdfplumber\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number):\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            return tables if tables else []\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number, pdf_path):\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTRect):\n",
        "            new_tables = self.parse_table(pdf_path, page_number)\n",
        "            tables.extend(new_tables)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content, tables = self.process_element(\n",
        "                    element, current_section, current_subsection, content, tables, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.result.append({\n",
        "                \"Document Name\": self.doc_name,\n",
        "                \"Title\": self.title,\n",
        "                \"Sections Heading\": current_section or \"\",\n",
        "                \"Subsections Heading\": current_subsection or \"\",\n",
        "                \"Raw Content\": \" \".join(content),\n",
        "                \"Page Number\": page_number,\n",
        "                \"Tables\": tables,\n",
        "                \"Images\": []\n",
        "            })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_13.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "0libQo6uW7oJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "pdf_path=\"/content/Quantum Computing_ Principles and Applications.pdf\"\n",
        "all_tables = []\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        tables = page.extract_tables()  # Extract tables from the current page\n",
        "        if tables:\n",
        "            all_tables.extend(tables)\n",
        "            print(page.page_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biGNuUo5xvic",
        "outputId": "0fa395c8-043e-46ff-88da-75eda78034ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "9\n",
            "10\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie9GEd5OIFJ6",
        "outputId": "8263a5c1-f5f5-4eca-ec43-1643467e05da"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['𝜓\\n𝑖𝑛1', '𝜓\\n𝑖𝑛2', '𝜓\\n𝑜𝑢𝑡1', '𝜓\\n𝑜𝑢𝑡2'],\n",
              "  ['0', '0', '0', '0'],\n",
              "  ['0', '1', '0', '1'],\n",
              "  ['1', '0', '1', '1'],\n",
              "  ['1', '1', '1', '0']],\n",
              " [['𝐼𝑁\\n1', '𝐼𝑁\\n2', '𝑂𝑢𝑡'],\n",
              "  ['0', '0', '1'],\n",
              "  ['0', '1', '1'],\n",
              "  ['1', '0', '1'],\n",
              "  ['1', '1', '0']],\n",
              " [['𝜓\\n𝑖𝑛1', '𝜓\\n𝑖𝑛2', '𝜓\\n𝑖𝑛3', '𝜓\\n𝑜𝑢𝑡1', '𝜓\\n𝑜𝑢𝑡2', '𝜓\\n𝑜𝑢𝑡3'],\n",
              "  ['0', '0', '1', '0', '0', '1'],\n",
              "  ['0', '1', '1', '0', '1', '1'],\n",
              "  ['1', '0', '1', '1', '0', '1'],\n",
              "  ['1', '1', '1', '1', '1', '0']],\n",
              " [['𝜓\\n𝑖𝑛1',\n",
              "   None,\n",
              "   None,\n",
              "   '𝜓\\n𝑖𝑛2',\n",
              "   None,\n",
              "   None,\n",
              "   '𝜓\\n𝑖𝑛3',\n",
              "   None,\n",
              "   None,\n",
              "   '𝜓\\n𝑜𝑢𝑡1',\n",
              "   None,\n",
              "   None,\n",
              "   '𝜓\\n𝑜𝑢𝑡2',\n",
              "   None,\n",
              "   None,\n",
              "   '𝜓\\n𝑜𝑢𝑡3',\n",
              "   None,\n",
              "   None],\n",
              "  ['0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None],\n",
              "  ['',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   ''],\n",
              "  ['0',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None],\n",
              "  ['',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   ''],\n",
              "  ['1',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None],\n",
              "  ['',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   ''],\n",
              "  ['1',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '0',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None,\n",
              "   '1',\n",
              "   None,\n",
              "   None],\n",
              "  ['',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '1',\n",
              "   '',\n",
              "   '',\n",
              "   '0',\n",
              "   '']],\n",
              " [['', 'Alice', None, None, 'Bob', None, None],\n",
              "  ['Chosen\\nBase',\n",
              "   'Random\\nBit\\nr\\ni',\n",
              "   'Rotation\\nAngle',\n",
              "   'Photon\\nState',\n",
              "   'Chosen\\nBase',\n",
              "   'Photon\\nState\\nafter PBS',\n",
              "   'Measured\\nResult'],\n",
              "  ['Horizontal\\n-Vertical\\n(H-V)', '0', '0°', '↔', 'H-V', '↔', '0'],\n",
              "  [None, None, None, None, 'D', '⤢ or ⤡', '?'],\n",
              "  [None, '1', '90°', '↕', 'H-V', '↕', '1'],\n",
              "  [None, None, None, None, 'D', '⤢ or ⤡', '?'],\n",
              "  ['Diagonal\\n(D)', '0', '45°', '⤢', 'H-V', '↔ or ↕', '?'],\n",
              "  [None, None, None, None, 'D', '⤢', '0'],\n",
              "  [None, '1', '135°', '⤡', 'H-V', '↔ or ↕', '?'],\n",
              "  [None, None, None, None, 'D', '⤡', '1']]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTFigure\n",
        "import pdfplumber\n",
        "import camelot\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table_with_pdfplumber(self, pdf_path, page_number):\n",
        "        \"\"\"Extract tables using pdfplumber.\"\"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables(\n",
        "                table_settings={\n",
        "                    \"vertical_strategy\": \"lines\",\n",
        "                    \"horizontal_strategy\": \"lines\",\n",
        "                    \"intersection_tolerance\": 5,\n",
        "                }\n",
        "            )\n",
        "            return tables if tables else []\n",
        "\n",
        "    def parse_table_with_camelot(self, pdf_path, page_number):\n",
        "        \"\"\"Extract tables using Camelot.\"\"\"\n",
        "        tables = camelot.read_pdf(\n",
        "            pdf_path, pages=str(page_number), flavor=\"stream\"\n",
        "        )  # Use \"stream\" for line-based tables\n",
        "        return [table.df.values.tolist() for table in tables] if tables else []\n",
        "\n",
        "    def parse_tables(self, pdf_path, page_number):\n",
        "        \"\"\"Combine both methods for table extraction.\"\"\"\n",
        "        tables = self.parse_table_with_pdfplumber(pdf_path, page_number)\n",
        "        if not tables:\n",
        "            tables = self.parse_table_with_camelot(pdf_path, page_number)\n",
        "        return tables\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number, pdf_path):\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            new_tables = self.parse_tables(pdf_path, page_number)\n",
        "            tables.extend(new_tables)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content, tables = self.process_element(\n",
        "                    element, current_section, current_subsection, content, tables, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.result.append({\n",
        "                \"Document Name\": self.doc_name,\n",
        "                \"Title\": self.title,\n",
        "                \"Sections Heading\": current_section or \"\",\n",
        "                \"Subsections Heading\": current_subsection or \"\",\n",
        "                \"Raw Content\": \" \".join(content),\n",
        "                \"Page Number\": page_number,\n",
        "                \"Tables\": tables,\n",
        "                \"Images\": []\n",
        "            })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/2309.07930v1.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_combined.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "nn63Tsp97xLj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTFigure\n",
        "import pdfplumber\n",
        "import camelot\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table_with_pdfplumber(self, pdf_path, page_number):\n",
        "        \"\"\"Extract tables using pdfplumber.\"\"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables(\n",
        "                table_settings={\n",
        "                    \"vertical_strategy\": \"lines\",\n",
        "                    \"horizontal_strategy\": \"lines\",\n",
        "                    \"intersection_tolerance\": 5,\n",
        "                }\n",
        "            )\n",
        "            return tables if tables else []\n",
        "\n",
        "    def parse_table_with_camelot(self, pdf_path, page_number):\n",
        "        \"\"\"Extract tables using Camelot.\"\"\"\n",
        "        tables = camelot.read_pdf(\n",
        "            pdf_path, pages=str(page_number), flavor=\"stream\"\n",
        "        )  # Use \"stream\" for line-based tables\n",
        "        return [table.df.values.tolist() for table in tables] if tables else []\n",
        "\n",
        "    def parse_tables(self, pdf_path, page_number):\n",
        "        \"\"\"Combine both methods for table extraction.\"\"\"\n",
        "        tables = self.parse_table_with_pdfplumber(pdf_path, page_number)\n",
        "        if not tables:\n",
        "            tables = self.parse_table_with_camelot(pdf_path, page_number)\n",
        "        return tables\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number, pdf_path):\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        elif isinstance(element, LTFigure):\n",
        "            # Recursively analyze nested elements within the figure\n",
        "            for sub_element in element:\n",
        "                if isinstance(sub_element, LTTextBox):\n",
        "                    for line in sub_element:\n",
        "                        if isinstance(line, LTTextLine):\n",
        "                            text = line.get_text().strip()\n",
        "                            content.append(text)\n",
        "\n",
        "            # Attempt table extraction for the current page using pdfplumber and camelot\n",
        "            new_tables = self.parse_tables(pdf_path, page_number)\n",
        "            if new_tables:\n",
        "                tables.extend(new_tables)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content, tables = self.process_element(\n",
        "                    element, current_section, current_subsection, content, tables, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.result.append({\n",
        "                \"Document Name\": self.doc_name,\n",
        "                \"Title\": self.title,\n",
        "                \"Sections Heading\": current_section or \"\",\n",
        "                \"Subsections Heading\": current_subsection or \"\",\n",
        "                \"Raw Content\": \" \".join(content),\n",
        "                \"Page Number\": page_number,\n",
        "                \"Tables\": tables,\n",
        "                \"Images\": []\n",
        "            })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/2309.07930v1.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_combined_1.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "xSjsaJf5-hit"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2TCm2LO4kpk",
        "outputId": "983dc821-3868-484a-9f2a-075ac9c68fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['a\\nTraining Discriminator\\nsamples\\nreal/fake?'],\n",
              "  ['Generator\\nz\\nTraining\\nReward model RLHF\\nHuman preference\\ndata\\nfeedback\\nSelf-supervised Supervised Conversational\\nLanguage model\\nlearning fine-tuning model\\ning Fine-tuning\\nmplesofdifferenttrainingproceduresforgenerativeAImodels. (a)Generativeadve\\nN)wherezisrandominput. (b)Reinforcementlearningfromhumanfeedback(RL\\nsationalgenerativeAImodels.']],\n",
              " [['', 'Reward model\\nHuman preference\\ndata']],\n",
              " [['', 'Self-supervised\\nLanguage model\\nlearning']]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install camelot-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls0qLWpM69LM",
        "outputId": "557eae54-218e-41c7-9c2c-624258b53549"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting camelot-py\n",
            "  Downloading camelot_py-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (8.1.7)\n",
            "Requirement already satisfied: chardet>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (1.26.4)\n",
            "Requirement already satisfied: openpyxl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (3.1.5)\n",
            "Collecting pdfminer-six>=20240706 (from camelot-py)\n",
            "  Using cached pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pypdf<4.0,>=3.17 (from camelot-py)\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (2.2.2)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (4.12.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (4.10.0.84)\n",
            "Requirement already satisfied: pypdfium2>=4 in /usr/local/lib/python3.10/dist-packages (from camelot-py) (4.30.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.1.0->camelot-py) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.2->camelot-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.2->camelot-py) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.2->camelot-py) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer-six>=20240706->camelot-py) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer-six>=20240706->camelot-py) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py) (2.22)\n",
            "Downloading camelot_py-1.0.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, pdfminer-six, camelot-py\n",
            "  Attempting uninstall: pdfminer-six\n",
            "    Found existing installation: pdfminer.six 20231228\n",
            "    Uninstalling pdfminer.six-20231228:\n",
            "      Successfully uninstalled pdfminer.six-20231228\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pdfplumber 0.11.5 requires pdfminer.six==20231228, but you have pdfminer-six 20240706 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed camelot-py-1.0.0 pdfminer-six-20240706 pypdf-3.17.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import camelot\n",
        "pdf_path=\"/content/2309.07930v1.pdf\"\n",
        "page_number = 6\n",
        "tables = camelot.read_pdf(pdf_path, pages=str(page_number), flavor='stream')\n",
        "for i, table in enumerate(tables):\n",
        "    print(f\"Table {i}:\\n\", table.df)\n",
        "    # Optionally, save the table to CSV\n",
        "    table.to_csv(f\"/content/table_{i}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prpJFpSb4njK",
        "outputId": "1bad6bff-a98d-4ca4-8603-e348ce6e37f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
            "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 0:\n",
            "                                    0  \\\n",
            "0                            Concept   \n",
            "1     Diffusion probabilistic models   \n",
            "2                                      \n",
            "3                                      \n",
            "4                                      \n",
            "5                                      \n",
            "6     Generative adversarial network   \n",
            "7                                      \n",
            "8                                      \n",
            "9                                      \n",
            "10                                     \n",
            "11                                     \n",
            "12            (Large) language model   \n",
            "13                                     \n",
            "14                                     \n",
            "15                                     \n",
            "16                                     \n",
            "17                                     \n",
            "18                                     \n",
            "19     Reinforcement\\nlearning\\nfrom   \n",
            "20                    human feedback   \n",
            "21                                     \n",
            "22                                     \n",
            "23                                     \n",
            "24                   Prompt learning   \n",
            "25                                     \n",
            "26                                     \n",
            "27                                     \n",
            "28                                     \n",
            "29                           seq2seq   \n",
            "30                                     \n",
            "31                                     \n",
            "32                                     \n",
            "33                                     \n",
            "34                                     \n",
            "35                       Transformer   \n",
            "36                                     \n",
            "37                                     \n",
            "38                                     \n",
            "39                                     \n",
            "40                                     \n",
            "41                                     \n",
            "42           Variational autoencoder   \n",
            "43                                     \n",
            "44                                     \n",
            "45                                     \n",
            "46                                     \n",
            "47  Zero-shot\\nlearning\\n/\\nfew-shot   \n",
            "48                          learning   \n",
            "49                                     \n",
            "50                                     \n",
            "51                                     \n",
            "\n",
            "                                                    1  \n",
            "0                                         Description  \n",
            "1   Diffusion probability models are a class of la...  \n",
            "2   Formally, diffusion probability models capture...  \n",
            "3   by statistical physics. Specifically,\\nthey ty...  \n",
            "4   generate a natural image. A notable variant is...  \n",
            "5              systems such as DALL-E and Midjourney.  \n",
            "6   A GAN is a class of neural network architectur...  \n",
            "7   two neural networks that contest with each oth...  \n",
            "8   Formally, the first network G is called the ge...  \n",
            "9   evaluates how likely the candidate samples com...  \n",
            "10  map from a latent space to a data distribution...  \n",
            "11                  data distribution (see Figure 2).  \n",
            "12  A (large) language model (LLM) refers to neura...  \n",
            "13  the language model uses a large-scale, sequent...  \n",
            "14  pre-trained through self-supervision in which ...  \n",
            "15  (e.g., next-word prediction). Third,\\nthe pre-...  \n",
            "16  Eventually,\\nthe language model may be fine-tu...  \n",
            "17  language generation). Recently, language model...  \n",
            "18  of massive LLMs are BERT (Devlin et al., 2018)...  \n",
            "19  RLHF learns sequential tasks (e.g., chat dialo...  \n",
            "20  a so-called reward model from human feedback a...  \n",
            "21  data-efficient and robust algorithms (Ziegler ...  \n",
            "22  chat messages, such that new answers accommoda...  \n",
            "23  preferences (e.g., length, style, appropriaten...  \n",
            "24  Prompt\\nlearning is a method for LLMs that use...  \n",
            "25  prompt\\nlearning does not require any fine-tun...  \n",
            "26  “) and then the most probable output s ∈ {“pos...  \n",
            "27  is picked. Recent advances allow for more comp...  \n",
            "28                                             2023).  \n",
            "29  The term sequence-to-sequence (seq2seq)\\nrefer...  \n",
            "30  (Sutskever et al., 2014). An example is machin...  \n",
            "31  main components: An encoder\\nturns each elemen...  \n",
            "32  element and its context. The decoder reverses ...  \n",
            "33  considering the previous output\\nto model depe...  \n",
            "34  mappings such as text-to-image or text-to-spee...  \n",
            "35  A transformer is a deep learning architecture ...  \n",
            "36  importance of each part of the input data. Lik...  \n",
            "37  as natural language, with applications for tas...  \n",
            "38  input all at once. The attention mechanism pro...  \n",
            "39  RNN in general) is a document embedding, which...  \n",
            "40  texts are located in closer proximity which ty...  \n",
            "41                                             2022).  \n",
            "42  A variational autoencoder (VAE) is a type of n...  \n",
            "43  into a compressed latent variable space and th...  \n",
            "44  autoencoders by using a probabilistic approach...  \n",
            "45  variation in the data and generate new data sa...  \n",
            "46  such as anomaly detection and data compression...  \n",
            "47  Zero-shot learning and few-shot learning refer...  \n",
            "48  learning is when a machine is taught how to le...  \n",
            "49  to when there are only a few specific examples...  \n",
            "50  setting up AI systems. LLMs are few-shot or ze...  \n",
            "51  the sentiment of reviews), which makes LLMs hi...  \n",
            "Table 1:\n",
            "                                                     0\n",
            "0                            2.2.2\\nSystem-Level View\n",
            "1   Any system consists of a number of elements th...\n",
            "2   generative AI systems,\\nthis comprises not onl...\n",
            "3   underlying infrastructure, user-facing compone...\n",
            "4   processing (e.g., for prompts). An example wou...\n",
            "5   (Chen et al., 2021),\\ninto a more interactive ...\n",
            "6   allows its users to code more efficiently. Sim...\n",
            "7   undisclosed X-to-image generation model that u...\n",
            "8   bots.\\nThus, generative AI systems embed the f...\n",
            "9   provide an interface for user interaction. Thi...\n",
            "10  its practicability and usability across real-w...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar, LTFigure, LTRect\n",
        "import pdfplumber\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def parse_table(self, pdf_path, page_number, table_num):\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            tables = page.extract_tables()\n",
        "            if tables and table_num < len(tables):\n",
        "                return tables[table_num]\n",
        "        return []\n",
        "\n",
        "    def table_converter(self, table):\n",
        "        table_string = ''\n",
        "        for row in table:\n",
        "            cleaned_row = [\n",
        "                item.replace('\\n', ' ') if item and '\\n' in item else 'None' if item is None else item\n",
        "                for item in row\n",
        "            ]\n",
        "            table_string += '|' + '|'.join(cleaned_row) + '|\\n'\n",
        "        return table_string.strip()\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number, pdf_path):\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        # elif isinstance(element, LTFigure):\n",
        "        #     # Fallback for tables in figures\n",
        "        #     new_tables = self.parse_table(pdf_path, page_number, 0)\n",
        "        #     tables.extend(new_tables)\n",
        "\n",
        "        elif isinstance(element, LTRect):\n",
        "            # Custom logic for table boundaries\n",
        "            new_tables = self.parse_table(pdf_path, page_number, 0)  # Adjust table_num as needed\n",
        "            # for table in new_tables:\n",
        "            #     table_string = self.table_converter(table)\n",
        "            tables.append(new_tables)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content, tables = self.process_element(\n",
        "                    element, current_section, current_subsection, content, tables, page_number, pdf_path\n",
        "                )\n",
        "\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.result.append({\n",
        "                \"Document Name\": self.doc_name,\n",
        "                \"Title\": self.title,\n",
        "                \"Sections Heading\": current_section or \"\",\n",
        "                \"Subsections Heading\": current_subsection or \"\",\n",
        "                \"Raw Content\": \" \".join(content),\n",
        "                \"Page Number\": page_number,\n",
        "                \"Tables\": tables,\n",
        "                \"Images\": []\n",
        "            })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/Quantum Computing_ Principles and Applications.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_17.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "wJf5pSyp65_M",
        "outputId": "24a5443f-7215-4541-a6d9-5a51b941c9fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e95e41e94fc4>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mparsed_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/parsed_content_17.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e95e41e94fc4>\u001b[0m in \u001b[0;36mparse_pdf\u001b[0;34m(self, pdf_path)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_layout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage_layout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 current_section, current_subsection, content, tables = self.process_element(\n\u001b[0m\u001b[1;32m    116\u001b[0m                     \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_section\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_subsection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 )\n",
            "\u001b[0;32m<ipython-input-4-e95e41e94fc4>\u001b[0m in \u001b[0;36mprocess_element\u001b[0;34m(self, element, current_section, current_subsection, content, tables, page_number, pdf_path)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLTRect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Custom logic for table boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mnew_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust table_num as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;31m# for table in new_tables:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m#     table_string = self.table_converter(table)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e95e41e94fc4>\u001b[0m in \u001b[0;36mparse_table\u001b[0;34m(self, pdf_path, page_number, table_num)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage_number\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, t, value, traceback)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTracebackType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     ) -> None:\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36mpages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages_to_parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFPage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mpage_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpage_number\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfpage.py\u001b[0m in \u001b[0;36mcreate_pages\u001b[0;34m(cls, document)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfpage.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, doc, pageid, attrs, label)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resources\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         mediabox_params: List[Any] = [\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mresolve1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediabox_param\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmediabox_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MediaBox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfpage.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         mediabox_params: List[Any] = [\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mresolve1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediabox_param\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmediabox_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MediaBox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         ]\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmediabox\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediabox_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdftypes.py\u001b[0m in \u001b[0;36mresolve1\u001b[0;34m(x, default)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0msome\u001b[0m \u001b[0mindirect\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0minside\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPDFObjRef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
        "import pdfplumber\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def extract_tables_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract tables and their locations using pdfplumber.\"\"\"\n",
        "        table_data = {}\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page_number, page in enumerate(pdf.pages, start=1):\n",
        "                tables = page.extract_tables()\n",
        "                if tables:\n",
        "                    table_data[page_number] = [\n",
        "                        {\"content\": table, \"bbox\": page.bbox} for table in tables\n",
        "                    ]\n",
        "        return table_data\n",
        "\n",
        "    def assign_tables_to_sections(self, page_number, table_data, current_section, current_subsection, content, page_layout):\n",
        "        \"\"\"Associate extracted tables with sections or subsections based on spatial proximity.\"\"\"\n",
        "        if page_number not in table_data:\n",
        "            return content, []\n",
        "\n",
        "        assigned_tables = []\n",
        "        unprocessed_content = list(content)  # Copy of raw content\n",
        "\n",
        "        for table in table_data[page_number]:\n",
        "            # Optionally refine the association logic based on specific bounding box relationships\n",
        "            assigned_tables.append(table[\"content\"])\n",
        "\n",
        "            # Optionally remove table-like content from raw content\n",
        "            # (Further customization can be added here)\n",
        "\n",
        "        return unprocessed_content, assigned_tables\n",
        "\n",
        "    # def assign_tables_to_sections(self, page_number, table_data, current_section, current_subsection, content, page_layout):\n",
        "    #     \"\"\"Associate extracted tables with sections or subsections based on spatial proximity and remove duplicates.\"\"\"\n",
        "    #     if page_number not in table_data:\n",
        "    #         return content, []\n",
        "\n",
        "    #     assigned_tables = []\n",
        "    #     updated_content = []\n",
        "\n",
        "    #     for table in table_data[page_number]:\n",
        "    #         table_bbox = table[\"bbox\"]\n",
        "    #         assigned_tables.append(table[\"content\"])\n",
        "\n",
        "    #         # Remove table-like content from raw_content by checking overlap\n",
        "    #         for element in page_layout:\n",
        "    #             if isinstance(element, LTTextBox):\n",
        "    #                 for line in element:\n",
        "    #                     if isinstance(line, LTTextLine):\n",
        "    #                         line_bbox = line.bbox\n",
        "    #                         if not (\n",
        "    #                             line_bbox[0] >= table_bbox[0]\n",
        "    #                             and line_bbox[1] >= table_bbox[1]\n",
        "    #                             and line_bbox[2] <= table_bbox[2]\n",
        "    #                             and line_bbox[3] <= table_bbox[3]\n",
        "    #                         ):\n",
        "    #                             updated_content.append(line.get_text().strip())\n",
        "\n",
        "    #     return updated_content, assigned_tables\n",
        "\n",
        "\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number, table_data, page_layout):\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section or \"\",\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.result.append({\n",
        "                                \"Document Name\": self.doc_name,\n",
        "                                \"Title\": self.title,\n",
        "                                \"Sections Heading\": current_section,\n",
        "                                \"Subsections Heading\": current_subsection or \"\",\n",
        "                                \"Raw Content\": \" \".join(content),\n",
        "                                \"Page Number\": page_number,\n",
        "                                \"Tables\": tables,\n",
        "                                \"Images\": []\n",
        "                            })\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        table_data = self.extract_tables_from_pdf(pdf_path)\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                current_section, current_subsection, content, tables = self.process_element(\n",
        "                    element, current_section, current_subsection, content, tables, page_number, table_data, page_layout\n",
        "                )\n",
        "\n",
        "            # After processing all elements on the page, assign tables to sections/subsections\n",
        "            content, page_tables = self.assign_tables_to_sections(\n",
        "                page_number, table_data, current_section, current_subsection, content, page_layout\n",
        "            )\n",
        "            tables.extend(page_tables)\n",
        "\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.result.append({\n",
        "                \"Document Name\": self.doc_name,\n",
        "                \"Title\": self.title,\n",
        "                \"Sections Heading\": current_section or \"\",\n",
        "                \"Subsections Heading\": current_subsection or \"\",\n",
        "                \"Raw Content\": \" \".join(content),\n",
        "                \"Page Number\": page_number,\n",
        "                \"Tables\": tables,\n",
        "                \"Images\": []\n",
        "            })\n",
        "\n",
        "        return self.result\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/1807.01544v2-2.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_19.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "LiupvyWsLEJX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def extract_tables_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract tables and their locations using pdfplumber.\"\"\"\n",
        "        table_data = {}\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page_number, page in enumerate(pdf.pages, start=1):\n",
        "                tables = page.extract_tables()\n",
        "                if tables:\n",
        "                    table_data[page_number] = [\n",
        "                        {\"content\": table, \"bbox\": page.bbox} for table in tables\n",
        "                    ]\n",
        "        return table_data\n",
        "\n",
        "    def process_element(self, element, current_section, current_subsection, content, tables, page_number):\n",
        "        \"\"\"Process individual PDF elements to determine structure and content.\"\"\"\n",
        "        if isinstance(element, LTTextBox):\n",
        "            for line in element:\n",
        "                if isinstance(line, LTTextLine):\n",
        "                    avg_font_size, font_style = self.identify_font(line)\n",
        "                    text = line.get_text().strip()\n",
        "                    heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                    if heading_type == \"title\":\n",
        "                        self.title += \" \" + text if self.title else text\n",
        "                    elif heading_type == \"section\":\n",
        "                        if current_section or content or tables:\n",
        "                            self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                        current_section = text\n",
        "                        current_subsection = None\n",
        "                        content, tables = [], []\n",
        "                    elif heading_type == \"subsection\":\n",
        "                        if current_subsection or content or tables:\n",
        "                            self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                        current_subsection = text\n",
        "                        content, tables = [], []\n",
        "                    else:\n",
        "                        content.append(text)\n",
        "\n",
        "        return current_section, current_subsection, content, tables\n",
        "\n",
        "    def add_section(self, current_section, current_subsection, content, tables, page_number):\n",
        "        \"\"\"Add a completed section or subsection to the result.\"\"\"\n",
        "        self.result.append({\n",
        "            \"Document Name\": self.doc_name,\n",
        "            \"Title\": self.title,\n",
        "            \"Sections Heading\": current_section or \"\",\n",
        "            \"Subsections Heading\": current_subsection or \"\",\n",
        "            \"Raw Content\": \" \".join(content),\n",
        "            \"Page Number\": page_number,\n",
        "            \"Tables\": tables,\n",
        "            \"Images\": []\n",
        "        })\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        table_data = self.extract_tables_from_pdf(pdf_path)\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "        section_headings = []  # Stores (bbox, text) for sections\n",
        "        subsection_headings = []  # Stores (bbox, text) for subsections\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                if isinstance(element, LTTextBox):\n",
        "                    for line in element:\n",
        "                        if isinstance(line, LTTextLine):\n",
        "                            avg_font_size, font_style = self.identify_font(line)\n",
        "                            text = line.get_text().strip()\n",
        "                            heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                            if heading_type == \"section\":\n",
        "                                if current_section or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_section = text\n",
        "                                current_subsection = None\n",
        "                                section_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            elif heading_type == \"subsection\":\n",
        "                                if current_subsection or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_subsection = text\n",
        "                                subsection_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            else:\n",
        "                                content.append(text)\n",
        "\n",
        "            # Assign tables to sections/subsections for the current page\n",
        "            table_assignments = self.assign_tables_to_sections(page_number, table_data, section_headings, subsection_headings)\n",
        "            for heading, tables_in_heading in table_assignments.items():\n",
        "                if heading == current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "                elif heading == current_section and not current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "\n",
        "        # Finalize the last section or subsection\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "\n",
        "        return self.result\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/1807.01544v2-2.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_20.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "STKjAnGYY9No",
        "outputId": "030fb04e-1215-421a-ae1d-2a3f23d1a1c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PDFParser' object has no attribute 'assign_tables_to_sections'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-61ee514f5442>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mparsed_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/parsed_content_20.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-61ee514f5442>\u001b[0m in \u001b[0;36mparse_pdf\u001b[0;34m(self, pdf_path)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# Assign tables to sections/subsections for the current page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mtable_assignments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_tables_to_sections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_headings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsection_headings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mheading\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables_in_heading\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_assignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mheading\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_subsection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PDFParser' object has no attribute 'assign_tables_to_sections'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def extract_tables_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract tables and their locations using pdfplumber.\"\"\"\n",
        "        table_data = {}\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page_number, page in enumerate(pdf.pages, start=1):\n",
        "                tables = page.extract_tables()\n",
        "                if tables:\n",
        "                    table_data[page_number] = [\n",
        "                        {\"content\": table, \"bbox\": page.bbox} for table in tables\n",
        "                    ]\n",
        "        return table_data\n",
        "\n",
        "    def assign_tables_to_sections(self, page_number, table_data, section_headings, subsection_headings):\n",
        "        \"\"\"Assign tables to sections/subsections based on proximity and page number.\"\"\"\n",
        "        assigned_tables = {}\n",
        "        if page_number not in table_data:\n",
        "            return assigned_tables\n",
        "\n",
        "        for table in table_data[page_number]:\n",
        "            table_bbox = table[\"bbox\"]\n",
        "\n",
        "            # Find the closest section or subsection heading based on bounding boxes\n",
        "            closest_heading = None\n",
        "            closest_distance = float(\"inf\")\n",
        "            for heading_bbox, heading_text in section_headings + subsection_headings:\n",
        "                # Compute vertical distance between table and heading\n",
        "                distance = abs(heading_bbox[1] - table_bbox[1])\n",
        "                if distance < closest_distance:\n",
        "                    closest_heading = heading_text\n",
        "                    closest_distance = distance\n",
        "\n",
        "            # Assign table to the closest heading\n",
        "            if closest_heading:\n",
        "                assigned_tables.setdefault(closest_heading, []).append(table[\"content\"])\n",
        "\n",
        "        return assigned_tables\n",
        "\n",
        "    def add_section(self, current_section, current_subsection, content, tables, page_number):\n",
        "        \"\"\"Add a completed section or subsection to the result.\"\"\"\n",
        "        self.result.append({\n",
        "            \"Document Name\": self.doc_name,\n",
        "            \"Title\": self.title,\n",
        "            \"Sections Heading\": current_section or \"\",\n",
        "            \"Subsections Heading\": current_subsection or \"\",\n",
        "            \"Raw Content\": \" \".join(content),\n",
        "            \"Page Number\": page_number,\n",
        "            \"Tables\": tables,\n",
        "            \"Images\": []\n",
        "        })\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        table_data = self.extract_tables_from_pdf(pdf_path)\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "        section_headings = []  # Stores (bbox, text) for sections\n",
        "        subsection_headings = []  # Stores (bbox, text) for subsections\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                if isinstance(element, LTTextBox):\n",
        "                    for line in element:\n",
        "                        if isinstance(line, LTTextLine):\n",
        "                            avg_font_size, font_style = self.identify_font(line)\n",
        "                            text = line.get_text().strip()\n",
        "                            heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                            if heading_type == \"section\":\n",
        "                                if current_section or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_section = text\n",
        "                                current_subsection = None\n",
        "                                section_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            elif heading_type == \"subsection\":\n",
        "                                if current_subsection or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_subsection = text\n",
        "                                subsection_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            else:\n",
        "                                content.append(text)\n",
        "\n",
        "            # Assign tables to sections/subsections for the current page\n",
        "            table_assignments = self.assign_tables_to_sections(page_number, table_data, section_headings, subsection_headings)\n",
        "            for heading, tables_in_heading in table_assignments.items():\n",
        "                if heading == current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "                elif heading == current_section and not current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "\n",
        "        # Finalize the last section or subsection\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "\n",
        "        return self.result\n",
        "\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/1807.01544v2-2.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_20.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n"
      ],
      "metadata": {
        "id": "chVHxFStPwAn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "class PDFParser:\n",
        "    def __init__(self, config_path, doc_name):\n",
        "        self.config = self.load_config(config_path)\n",
        "        self.doc_name = doc_name\n",
        "        self.result = []\n",
        "        self.title = \"\"\n",
        "\n",
        "    def load_config(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def identify_font(self, line):\n",
        "        font_sizes = []\n",
        "        font_styles = set()\n",
        "        for char in line:\n",
        "            if isinstance(char, LTChar):\n",
        "                font_sizes.append(round(char.size))\n",
        "                font_styles.add(char.fontname)\n",
        "        avg_font_size = round(sum(font_sizes) / len(font_sizes)) if font_sizes else 0\n",
        "        font_style = next(iter(font_styles), None) if font_styles else \"\"\n",
        "        return avg_font_size, font_style\n",
        "\n",
        "    def match_heading(self, avg_font_size, font_style):\n",
        "        for heading_type, attributes in self.config.items():\n",
        "            if avg_font_size == attributes['font_size'] and attributes['font_style'] == font_style:\n",
        "                return heading_type\n",
        "        return None\n",
        "\n",
        "    def extract_tables_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract tables and their locations using pdfplumber.\"\"\"\n",
        "        table_data = {}\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page_number, page in enumerate(pdf.pages, start=1):\n",
        "                tables = page.extract_tables()\n",
        "                if tables:\n",
        "                    table_data[page_number] = [\n",
        "                        {\"content\": table, \"bbox\": page.bbox} for table in tables\n",
        "                    ]\n",
        "        return table_data\n",
        "\n",
        "    def assign_tables_to_sections(self, page_number, table_data, section_headings, subsection_headings):\n",
        "        \"\"\"Assign tables to sections/subsections based on proximity and page number.\"\"\"\n",
        "        assigned_tables = {}\n",
        "        if page_number not in table_data:\n",
        "            return assigned_tables\n",
        "\n",
        "        for table in table_data[page_number]:\n",
        "            table_bbox = table[\"bbox\"]\n",
        "\n",
        "            # Find the closest section or subsection heading based on bounding boxes\n",
        "            closest_heading = None\n",
        "            closest_distance = float(\"inf\")\n",
        "            for heading_bbox, heading_text in section_headings + subsection_headings:\n",
        "                # Compute vertical distance between table and heading\n",
        "                heading_y_center = (heading_bbox[1] + heading_bbox[3]) / 2\n",
        "                table_y_center = (table_bbox[1] + table_bbox[3]) / 2\n",
        "                distance = abs(heading_y_center - table_y_center)\n",
        "                if distance < closest_distance:\n",
        "                    closest_heading = heading_text\n",
        "                    closest_distance = distance\n",
        "\n",
        "            # Assign table to the closest heading\n",
        "            if closest_heading:\n",
        "                assigned_tables.setdefault(closest_heading, []).append(table[\"content\"])\n",
        "\n",
        "        return assigned_tables\n",
        "\n",
        "    def add_section(self, current_section, current_subsection, content, tables, page_number):\n",
        "        \"\"\"Add a completed section or subsection to the result.\"\"\"\n",
        "        self.result.append({\n",
        "            \"Document Name\": self.doc_name,\n",
        "            \"Title\": self.title,\n",
        "            \"Sections Heading\": current_section or \"\",\n",
        "            \"Subsections Heading\": current_subsection or \"\",\n",
        "            \"Raw Content\": \" \".join(content),\n",
        "            \"Page Number\": page_number,\n",
        "            \"Tables\": tables,\n",
        "            \"Images\": []\n",
        "        })\n",
        "\n",
        "    def parse_pdf(self, pdf_path):\n",
        "        table_data = self.extract_tables_from_pdf(pdf_path)\n",
        "        current_section = None\n",
        "        current_subsection = None\n",
        "        content, tables = [], []\n",
        "        section_headings = []  # Stores (bbox, text) for sections\n",
        "        subsection_headings = []  # Stores (bbox, text) for subsections\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                if isinstance(element, LTTextBox):\n",
        "                    for line in element:\n",
        "                        if isinstance(line, LTTextLine):\n",
        "                            avg_font_size, font_style = self.identify_font(line)\n",
        "                            text = line.get_text().strip()\n",
        "                            heading_type = self.match_heading(avg_font_size, font_style)\n",
        "\n",
        "                            if heading_type == \"section\":\n",
        "                                if current_section or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_section = text\n",
        "                                current_subsection = None\n",
        "                                section_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            elif heading_type == \"subsection\":\n",
        "                                if current_subsection or content or tables:\n",
        "                                    self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "                                current_subsection = text\n",
        "                                subsection_headings.append((line.bbox, text))\n",
        "                                content, tables = [], []\n",
        "                            else:\n",
        "                                content.append(text)\n",
        "\n",
        "            # Assign tables to sections/subsections for the current page\n",
        "            table_assignments = self.assign_tables_to_sections(page_number, table_data, section_headings, subsection_headings)\n",
        "            for heading, tables_in_heading in table_assignments.items():\n",
        "                if heading == current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "                elif heading == current_section and not current_subsection:\n",
        "                    tables.extend(tables_in_heading)\n",
        "\n",
        "        # Finalize the last section or subsection\n",
        "        if current_section or current_subsection or content or tables:\n",
        "            self.add_section(current_section, current_subsection, content, tables, page_number)\n",
        "\n",
        "        return self.result\n",
        "\n",
        "\n",
        "config_path = \"/content/config.json\"\n",
        "pdf_path = \"/content/1807.01544v2-2.pdf\"\n",
        "doc_name = \"Example Document\"\n",
        "\n",
        "parser = PDFParser(config_path, doc_name)\n",
        "parsed_content = parser.parse_pdf(pdf_path)\n",
        "\n",
        "with open(\"/content/parsed_content_21.json\", \"w\") as f:\n",
        "    json.dump(parsed_content, f, indent=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "BmAPZaLuQQkB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import pdfplumber\n",
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextBox, LTTextLine\n",
        "\n",
        "class DebugPDFParser(PDFParser):\n",
        "    def visualize_page(self, pdf_path, page_number, tables, headings):\n",
        "        \"\"\"Visualize tables and headings on a PDF page.\"\"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            page = pdf.pages[page_number - 1]\n",
        "            im = page.to_image()\n",
        "\n",
        "            # Create a Matplotlib figure\n",
        "            fig, ax = plt.subplots(1, figsize=(10, 15))\n",
        "            ax.imshow(im.original)\n",
        "\n",
        "            # Draw table bounding boxes\n",
        "            for table in tables:\n",
        "                x0, y0, x1, y1 = table[\"bbox\"]\n",
        "                rect = Rectangle(\n",
        "                    (x0, im.original.size[1] - y1),\n",
        "                    x1 - x0,\n",
        "                    y1 - y0,\n",
        "                    edgecolor=\"blue\",\n",
        "                    facecolor=\"none\",\n",
        "                    linewidth=2,\n",
        "                    label=\"Table\" if \"Table\" not in [p.get_label() for p in ax.patches] else \"\"\n",
        "                )\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "            # Draw heading bounding boxes\n",
        "            for bbox, text in headings:\n",
        "                x0, y0, x1, y1 = bbox\n",
        "                rect = Rectangle(\n",
        "                    (x0, im.original.size[1] - y1),\n",
        "                    x1 - x0,\n",
        "                    y1 - y0,\n",
        "                    edgecolor=\"red\",\n",
        "                    facecolor=\"none\",\n",
        "                    linewidth=2,\n",
        "                    label=\"Heading\" if \"Heading\" not in [p.get_label() for p in ax.patches] else \"\"\n",
        "                )\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "            ax.legend(loc=\"upper right\")\n",
        "            plt.title(f\"Visualization for Page {page_number}\")\n",
        "            plt.show()\n",
        "\n",
        "    def debug_parse_pdf(self, pdf_path):\n",
        "        table_data = self.extract_tables_from_pdf(pdf_path)\n",
        "        section_headings = []  # (bbox, text)\n",
        "        subsection_headings = []  # (bbox, text)\n",
        "\n",
        "        for page_number, page_layout in enumerate(extract_pages(pdf_path), start=1):\n",
        "            for element in page_layout:\n",
        "                if isinstance(element, LTTextBox):\n",
        "                    for\n"
      ],
      "metadata": {
        "id": "h6TISTqIRddG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}